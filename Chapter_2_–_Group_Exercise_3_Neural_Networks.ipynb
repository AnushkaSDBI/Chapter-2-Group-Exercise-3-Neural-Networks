{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ASSIGNMENT\n",
        "# Chapter 2 – Group Exercise 3: Neural Networks\n",
        "## Group Members\n",
        "\n",
        "| Name | Matriculation Number |\n",
        "|------|----------------------|\n",
        "| Arya Shinde | 100006646 (co-ordinator) |\n",
        "| Mirang Bhandari | 100007049 |\n",
        "| Yash Annapure | 100006547 |\n",
        "| Anushka Sawant | 100006644 |"
      ],
      "metadata": {
        "id": "4Fs1_B1hB3Ao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Packages"
      ],
      "metadata": {
        "id": "LQ-Cs3-NBzpB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ibC8etKpPCNJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, confusion_matrix, classification_report,\n",
        "    roc_curve, auc\n",
        ")\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h7PlwdCFfhM",
        "outputId": "6c467b5f-eba9-4c2e-92bf-a398499fee19"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please run this file in Google Colab as Tensorflow might not be compatible with Python 3.13 version in some cases."
      ],
      "metadata": {
        "id": "8PfdntmF__Bg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "YO67kZM-X6RX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = fetch_ucirepo(id=572)\n",
        "\n",
        "df = pd.DataFrame(data=dataset.data.features, columns=dataset.data.feature_names)\n",
        "df['Bankrupt?'] = dataset.data.targets.values"
      ],
      "metadata": {
        "id": "CTQKxLkYH3Tn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "MOGQJfoHIGKx",
        "outputId": "7d86f59b-9bdd-4e9e-c3e4-b7743fc5f166"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ROA(C) before interest and depreciation before interest  \\\n",
              "0                                              0.370594          \n",
              "1                                              0.464291          \n",
              "2                                              0.426071          \n",
              "3                                              0.399844          \n",
              "4                                              0.465022          \n",
              "...                                                 ...          \n",
              "6814                                           0.493687          \n",
              "6815                                           0.475162          \n",
              "6816                                           0.472725          \n",
              "6817                                           0.506264          \n",
              "6818                                           0.493053          \n",
              "\n",
              "       ROA(A) before interest and % after tax  \\\n",
              "0                                    0.424389   \n",
              "1                                    0.538214   \n",
              "2                                    0.499019   \n",
              "3                                    0.451265   \n",
              "4                                    0.538432   \n",
              "...                                       ...   \n",
              "6814                                 0.539468   \n",
              "6815                                 0.538269   \n",
              "6816                                 0.533744   \n",
              "6817                                 0.559911   \n",
              "6818                                 0.570105   \n",
              "\n",
              "       ROA(B) before interest and depreciation after tax  \\\n",
              "0                                              0.405750    \n",
              "1                                              0.516730    \n",
              "2                                              0.472295    \n",
              "3                                              0.457733    \n",
              "4                                              0.522298    \n",
              "...                                                 ...    \n",
              "6814                                           0.543230    \n",
              "6815                                           0.524172    \n",
              "6816                                           0.520638    \n",
              "6817                                           0.554045    \n",
              "6818                                           0.549548    \n",
              "\n",
              "       Operating Gross Margin   Realized Sales Gross Margin  \\\n",
              "0                    0.601457                      0.601457   \n",
              "1                    0.610235                      0.610235   \n",
              "2                    0.601450                      0.601364   \n",
              "3                    0.583541                      0.583541   \n",
              "4                    0.598783                      0.598783   \n",
              "...                       ...                           ...   \n",
              "6814                 0.604455                      0.604462   \n",
              "6815                 0.598308                      0.598308   \n",
              "6816                 0.610444                      0.610213   \n",
              "6817                 0.607850                      0.607850   \n",
              "6818                 0.627409                      0.627409   \n",
              "\n",
              "       Operating Profit Rate   Pre-tax net Interest Rate  \\\n",
              "0                   0.998969                    0.796887   \n",
              "1                   0.998946                    0.797380   \n",
              "2                   0.998857                    0.796403   \n",
              "3                   0.998700                    0.796967   \n",
              "4                   0.998973                    0.797366   \n",
              "...                      ...                         ...   \n",
              "6814                0.998992                    0.797409   \n",
              "6815                0.998992                    0.797414   \n",
              "6816                0.998984                    0.797401   \n",
              "6817                0.999074                    0.797500   \n",
              "6818                0.998080                    0.801987   \n",
              "\n",
              "       After-tax net Interest Rate  \\\n",
              "0                         0.808809   \n",
              "1                         0.809301   \n",
              "2                         0.808388   \n",
              "3                         0.808966   \n",
              "4                         0.809304   \n",
              "...                            ...   \n",
              "6814                      0.809331   \n",
              "6815                      0.809327   \n",
              "6816                      0.809317   \n",
              "6817                      0.809399   \n",
              "6818                      0.813800   \n",
              "\n",
              "       Non-industry income and expenditure/revenue  \\\n",
              "0                                         0.302646   \n",
              "1                                         0.303556   \n",
              "2                                         0.302035   \n",
              "3                                         0.303350   \n",
              "4                                         0.303475   \n",
              "...                                            ...   \n",
              "6814                                      0.303510   \n",
              "6815                                      0.303520   \n",
              "6816                                      0.303512   \n",
              "6817                                      0.303498   \n",
              "6818                                      0.313415   \n",
              "\n",
              "       Continuous interest rate (after tax)  ...   Total assets to GNP price  \\\n",
              "0                                  0.780985  ...                    0.009219   \n",
              "1                                  0.781506  ...                    0.008323   \n",
              "2                                  0.780284  ...                    0.040003   \n",
              "3                                  0.781241  ...                    0.003252   \n",
              "4                                  0.781550  ...                    0.003878   \n",
              "...                                     ...  ...                         ...   \n",
              "6814                               0.781588  ...                    0.000466   \n",
              "6815                               0.781586  ...                    0.001959   \n",
              "6816                               0.781546  ...                    0.002840   \n",
              "6817                               0.781663  ...                    0.002837   \n",
              "6818                               0.786079  ...                    0.000707   \n",
              "\n",
              "       No-credit Interval   Gross Profit to Sales  \\\n",
              "0                0.622879                0.601453   \n",
              "1                0.623652                0.610237   \n",
              "2                0.623841                0.601449   \n",
              "3                0.622929                0.583538   \n",
              "4                0.623521                0.598782   \n",
              "...                   ...                     ...   \n",
              "6814             0.623620                0.604455   \n",
              "6815             0.623931                0.598306   \n",
              "6816             0.624156                0.610441   \n",
              "6817             0.623957                0.607846   \n",
              "6818             0.626680                0.627408   \n",
              "\n",
              "       Net Income to Stockholder's Equity   Liability to Equity  \\\n",
              "0                                0.827890              0.290202   \n",
              "1                                0.839969              0.283846   \n",
              "2                                0.836774              0.290189   \n",
              "3                                0.834697              0.281721   \n",
              "4                                0.839973              0.278514   \n",
              "...                                   ...                   ...   \n",
              "6814                             0.840359              0.279606   \n",
              "6815                             0.840306              0.278132   \n",
              "6816                             0.840138              0.275789   \n",
              "6817                             0.841084              0.277547   \n",
              "6818                             0.841019              0.275114   \n",
              "\n",
              "       Degree of Financial Leverage (DFL)  \\\n",
              "0                                0.026601   \n",
              "1                                0.264577   \n",
              "2                                0.026555   \n",
              "3                                0.026697   \n",
              "4                                0.024752   \n",
              "...                                   ...   \n",
              "6814                             0.027064   \n",
              "6815                             0.027009   \n",
              "6816                             0.026791   \n",
              "6817                             0.026822   \n",
              "6818                             0.026793   \n",
              "\n",
              "       Interest Coverage Ratio (Interest expense to EBIT)   Net Income Flag  \\\n",
              "0                                              0.564050                   1   \n",
              "1                                              0.570175                   1   \n",
              "2                                              0.563706                   1   \n",
              "3                                              0.564663                   1   \n",
              "4                                              0.575617                   1   \n",
              "...                                                 ...                 ...   \n",
              "6814                                           0.566193                   1   \n",
              "6815                                           0.566018                   1   \n",
              "6816                                           0.565158                   1   \n",
              "6817                                           0.565302                   1   \n",
              "6818                                           0.565167                   1   \n",
              "\n",
              "       Equity to Liability  Bankrupt?  \n",
              "0                 0.016469          1  \n",
              "1                 0.020794          1  \n",
              "2                 0.016474          1  \n",
              "3                 0.023982          1  \n",
              "4                 0.035490          1  \n",
              "...                    ...        ...  \n",
              "6814              0.029890          0  \n",
              "6815              0.038284          0  \n",
              "6816              0.097649          0  \n",
              "6817              0.044009          0  \n",
              "6818              0.233902          0  \n",
              "\n",
              "[6819 rows x 96 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e059b0f-95a7-43be-9766-0b3bb0d818df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ROA(C) before interest and depreciation before interest</th>\n",
              "      <th>ROA(A) before interest and % after tax</th>\n",
              "      <th>ROA(B) before interest and depreciation after tax</th>\n",
              "      <th>Operating Gross Margin</th>\n",
              "      <th>Realized Sales Gross Margin</th>\n",
              "      <th>Operating Profit Rate</th>\n",
              "      <th>Pre-tax net Interest Rate</th>\n",
              "      <th>After-tax net Interest Rate</th>\n",
              "      <th>Non-industry income and expenditure/revenue</th>\n",
              "      <th>Continuous interest rate (after tax)</th>\n",
              "      <th>...</th>\n",
              "      <th>Total assets to GNP price</th>\n",
              "      <th>No-credit Interval</th>\n",
              "      <th>Gross Profit to Sales</th>\n",
              "      <th>Net Income to Stockholder's Equity</th>\n",
              "      <th>Liability to Equity</th>\n",
              "      <th>Degree of Financial Leverage (DFL)</th>\n",
              "      <th>Interest Coverage Ratio (Interest expense to EBIT)</th>\n",
              "      <th>Net Income Flag</th>\n",
              "      <th>Equity to Liability</th>\n",
              "      <th>Bankrupt?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.370594</td>\n",
              "      <td>0.424389</td>\n",
              "      <td>0.405750</td>\n",
              "      <td>0.601457</td>\n",
              "      <td>0.601457</td>\n",
              "      <td>0.998969</td>\n",
              "      <td>0.796887</td>\n",
              "      <td>0.808809</td>\n",
              "      <td>0.302646</td>\n",
              "      <td>0.780985</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009219</td>\n",
              "      <td>0.622879</td>\n",
              "      <td>0.601453</td>\n",
              "      <td>0.827890</td>\n",
              "      <td>0.290202</td>\n",
              "      <td>0.026601</td>\n",
              "      <td>0.564050</td>\n",
              "      <td>1</td>\n",
              "      <td>0.016469</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.464291</td>\n",
              "      <td>0.538214</td>\n",
              "      <td>0.516730</td>\n",
              "      <td>0.610235</td>\n",
              "      <td>0.610235</td>\n",
              "      <td>0.998946</td>\n",
              "      <td>0.797380</td>\n",
              "      <td>0.809301</td>\n",
              "      <td>0.303556</td>\n",
              "      <td>0.781506</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008323</td>\n",
              "      <td>0.623652</td>\n",
              "      <td>0.610237</td>\n",
              "      <td>0.839969</td>\n",
              "      <td>0.283846</td>\n",
              "      <td>0.264577</td>\n",
              "      <td>0.570175</td>\n",
              "      <td>1</td>\n",
              "      <td>0.020794</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.426071</td>\n",
              "      <td>0.499019</td>\n",
              "      <td>0.472295</td>\n",
              "      <td>0.601450</td>\n",
              "      <td>0.601364</td>\n",
              "      <td>0.998857</td>\n",
              "      <td>0.796403</td>\n",
              "      <td>0.808388</td>\n",
              "      <td>0.302035</td>\n",
              "      <td>0.780284</td>\n",
              "      <td>...</td>\n",
              "      <td>0.040003</td>\n",
              "      <td>0.623841</td>\n",
              "      <td>0.601449</td>\n",
              "      <td>0.836774</td>\n",
              "      <td>0.290189</td>\n",
              "      <td>0.026555</td>\n",
              "      <td>0.563706</td>\n",
              "      <td>1</td>\n",
              "      <td>0.016474</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.399844</td>\n",
              "      <td>0.451265</td>\n",
              "      <td>0.457733</td>\n",
              "      <td>0.583541</td>\n",
              "      <td>0.583541</td>\n",
              "      <td>0.998700</td>\n",
              "      <td>0.796967</td>\n",
              "      <td>0.808966</td>\n",
              "      <td>0.303350</td>\n",
              "      <td>0.781241</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003252</td>\n",
              "      <td>0.622929</td>\n",
              "      <td>0.583538</td>\n",
              "      <td>0.834697</td>\n",
              "      <td>0.281721</td>\n",
              "      <td>0.026697</td>\n",
              "      <td>0.564663</td>\n",
              "      <td>1</td>\n",
              "      <td>0.023982</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.465022</td>\n",
              "      <td>0.538432</td>\n",
              "      <td>0.522298</td>\n",
              "      <td>0.598783</td>\n",
              "      <td>0.598783</td>\n",
              "      <td>0.998973</td>\n",
              "      <td>0.797366</td>\n",
              "      <td>0.809304</td>\n",
              "      <td>0.303475</td>\n",
              "      <td>0.781550</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003878</td>\n",
              "      <td>0.623521</td>\n",
              "      <td>0.598782</td>\n",
              "      <td>0.839973</td>\n",
              "      <td>0.278514</td>\n",
              "      <td>0.024752</td>\n",
              "      <td>0.575617</td>\n",
              "      <td>1</td>\n",
              "      <td>0.035490</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6814</th>\n",
              "      <td>0.493687</td>\n",
              "      <td>0.539468</td>\n",
              "      <td>0.543230</td>\n",
              "      <td>0.604455</td>\n",
              "      <td>0.604462</td>\n",
              "      <td>0.998992</td>\n",
              "      <td>0.797409</td>\n",
              "      <td>0.809331</td>\n",
              "      <td>0.303510</td>\n",
              "      <td>0.781588</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000466</td>\n",
              "      <td>0.623620</td>\n",
              "      <td>0.604455</td>\n",
              "      <td>0.840359</td>\n",
              "      <td>0.279606</td>\n",
              "      <td>0.027064</td>\n",
              "      <td>0.566193</td>\n",
              "      <td>1</td>\n",
              "      <td>0.029890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6815</th>\n",
              "      <td>0.475162</td>\n",
              "      <td>0.538269</td>\n",
              "      <td>0.524172</td>\n",
              "      <td>0.598308</td>\n",
              "      <td>0.598308</td>\n",
              "      <td>0.998992</td>\n",
              "      <td>0.797414</td>\n",
              "      <td>0.809327</td>\n",
              "      <td>0.303520</td>\n",
              "      <td>0.781586</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001959</td>\n",
              "      <td>0.623931</td>\n",
              "      <td>0.598306</td>\n",
              "      <td>0.840306</td>\n",
              "      <td>0.278132</td>\n",
              "      <td>0.027009</td>\n",
              "      <td>0.566018</td>\n",
              "      <td>1</td>\n",
              "      <td>0.038284</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6816</th>\n",
              "      <td>0.472725</td>\n",
              "      <td>0.533744</td>\n",
              "      <td>0.520638</td>\n",
              "      <td>0.610444</td>\n",
              "      <td>0.610213</td>\n",
              "      <td>0.998984</td>\n",
              "      <td>0.797401</td>\n",
              "      <td>0.809317</td>\n",
              "      <td>0.303512</td>\n",
              "      <td>0.781546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002840</td>\n",
              "      <td>0.624156</td>\n",
              "      <td>0.610441</td>\n",
              "      <td>0.840138</td>\n",
              "      <td>0.275789</td>\n",
              "      <td>0.026791</td>\n",
              "      <td>0.565158</td>\n",
              "      <td>1</td>\n",
              "      <td>0.097649</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6817</th>\n",
              "      <td>0.506264</td>\n",
              "      <td>0.559911</td>\n",
              "      <td>0.554045</td>\n",
              "      <td>0.607850</td>\n",
              "      <td>0.607850</td>\n",
              "      <td>0.999074</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.809399</td>\n",
              "      <td>0.303498</td>\n",
              "      <td>0.781663</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002837</td>\n",
              "      <td>0.623957</td>\n",
              "      <td>0.607846</td>\n",
              "      <td>0.841084</td>\n",
              "      <td>0.277547</td>\n",
              "      <td>0.026822</td>\n",
              "      <td>0.565302</td>\n",
              "      <td>1</td>\n",
              "      <td>0.044009</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6818</th>\n",
              "      <td>0.493053</td>\n",
              "      <td>0.570105</td>\n",
              "      <td>0.549548</td>\n",
              "      <td>0.627409</td>\n",
              "      <td>0.627409</td>\n",
              "      <td>0.998080</td>\n",
              "      <td>0.801987</td>\n",
              "      <td>0.813800</td>\n",
              "      <td>0.313415</td>\n",
              "      <td>0.786079</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000707</td>\n",
              "      <td>0.626680</td>\n",
              "      <td>0.627408</td>\n",
              "      <td>0.841019</td>\n",
              "      <td>0.275114</td>\n",
              "      <td>0.026793</td>\n",
              "      <td>0.565167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.233902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6819 rows × 96 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e059b0f-95a7-43be-9766-0b3bb0d818df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e059b0f-95a7-43be-9766-0b3bb0d818df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e059b0f-95a7-43be-9766-0b3bb0d818df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_35d1e939-4d78-4e94-9197-ae8de93d7497\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_35d1e939-4d78-4e94-9197-ae8de93d7497 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n Dataset Shape: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFT5zU8aV88a",
        "outputId": "6292238c-5b24-4d79-e2bf-4738a04f8820"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Dataset Shape: (6819, 96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n Dataset Description: {df.describe()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EmF5CAoWDqt",
        "outputId": "262ee89a-21f2-4d0d-c8e0-7cc4dbc200b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Dataset Description:         ROA(C) before interest and depreciation before interest  \\\n",
            "count                                        6819.000000          \n",
            "mean                                            0.505180          \n",
            "std                                             0.060686          \n",
            "min                                             0.000000          \n",
            "25%                                             0.476527          \n",
            "50%                                             0.502706          \n",
            "75%                                             0.535563          \n",
            "max                                             1.000000          \n",
            "\n",
            "        ROA(A) before interest and % after tax  \\\n",
            "count                              6819.000000   \n",
            "mean                                  0.558625   \n",
            "std                                   0.065620   \n",
            "min                                   0.000000   \n",
            "25%                                   0.535543   \n",
            "50%                                   0.559802   \n",
            "75%                                   0.589157   \n",
            "max                                   1.000000   \n",
            "\n",
            "        ROA(B) before interest and depreciation after tax  \\\n",
            "count                                        6819.000000    \n",
            "mean                                            0.553589    \n",
            "std                                             0.061595    \n",
            "min                                             0.000000    \n",
            "25%                                             0.527277    \n",
            "50%                                             0.552278    \n",
            "75%                                             0.584105    \n",
            "max                                             1.000000    \n",
            "\n",
            "        Operating Gross Margin   Realized Sales Gross Margin  \\\n",
            "count              6819.000000                   6819.000000   \n",
            "mean                  0.607948                      0.607929   \n",
            "std                   0.016934                      0.016916   \n",
            "min                   0.000000                      0.000000   \n",
            "25%                   0.600445                      0.600434   \n",
            "50%                   0.605997                      0.605976   \n",
            "75%                   0.613914                      0.613842   \n",
            "max                   1.000000                      1.000000   \n",
            "\n",
            "        Operating Profit Rate   Pre-tax net Interest Rate  \\\n",
            "count             6819.000000                 6819.000000   \n",
            "mean                 0.998755                    0.797190   \n",
            "std                  0.013010                    0.012869   \n",
            "min                  0.000000                    0.000000   \n",
            "25%                  0.998969                    0.797386   \n",
            "50%                  0.999022                    0.797464   \n",
            "75%                  0.999095                    0.797579   \n",
            "max                  1.000000                    1.000000   \n",
            "\n",
            "        After-tax net Interest Rate  \\\n",
            "count                   6819.000000   \n",
            "mean                       0.809084   \n",
            "std                        0.013601   \n",
            "min                        0.000000   \n",
            "25%                        0.809312   \n",
            "50%                        0.809375   \n",
            "75%                        0.809469   \n",
            "max                        1.000000   \n",
            "\n",
            "        Non-industry income and expenditure/revenue  \\\n",
            "count                                   6819.000000   \n",
            "mean                                       0.303623   \n",
            "std                                        0.011163   \n",
            "min                                        0.000000   \n",
            "25%                                        0.303466   \n",
            "50%                                        0.303525   \n",
            "75%                                        0.303585   \n",
            "max                                        1.000000   \n",
            "\n",
            "        Continuous interest rate (after tax)  ...   Total assets to GNP price  \\\n",
            "count                            6819.000000  ...                6.819000e+03   \n",
            "mean                                0.781381  ...                1.862942e+07   \n",
            "std                                 0.012679  ...                3.764501e+08   \n",
            "min                                 0.000000  ...                0.000000e+00   \n",
            "25%                                 0.781567  ...                9.036205e-04   \n",
            "50%                                 0.781635  ...                2.085213e-03   \n",
            "75%                                 0.781735  ...                5.269777e-03   \n",
            "max                                 1.000000  ...                9.820000e+09   \n",
            "\n",
            "        No-credit Interval   Gross Profit to Sales  \\\n",
            "count          6819.000000             6819.000000   \n",
            "mean              0.623915                0.607946   \n",
            "std               0.012290                0.016934   \n",
            "min               0.000000                0.000000   \n",
            "25%               0.623636                0.600443   \n",
            "50%               0.623879                0.605998   \n",
            "75%               0.624168                0.613913   \n",
            "max               1.000000                1.000000   \n",
            "\n",
            "        Net Income to Stockholder's Equity   Liability to Equity  \\\n",
            "count                          6819.000000           6819.000000   \n",
            "mean                              0.840402              0.280365   \n",
            "std                               0.014523              0.014463   \n",
            "min                               0.000000              0.000000   \n",
            "25%                               0.840115              0.276944   \n",
            "50%                               0.841179              0.278778   \n",
            "75%                               0.842357              0.281449   \n",
            "max                               1.000000              1.000000   \n",
            "\n",
            "        Degree of Financial Leverage (DFL)  \\\n",
            "count                          6819.000000   \n",
            "mean                              0.027541   \n",
            "std                               0.015668   \n",
            "min                               0.000000   \n",
            "25%                               0.026791   \n",
            "50%                               0.026808   \n",
            "75%                               0.026913   \n",
            "max                               1.000000   \n",
            "\n",
            "        Interest Coverage Ratio (Interest expense to EBIT)   Net Income Flag  \\\n",
            "count                                        6819.000000              6819.0   \n",
            "mean                                            0.565358                 1.0   \n",
            "std                                             0.013214                 0.0   \n",
            "min                                             0.000000                 1.0   \n",
            "25%                                             0.565158                 1.0   \n",
            "50%                                             0.565252                 1.0   \n",
            "75%                                             0.565725                 1.0   \n",
            "max                                             1.000000                 1.0   \n",
            "\n",
            "        Equity to Liability    Bankrupt?  \n",
            "count           6819.000000  6819.000000  \n",
            "mean               0.047578     0.032263  \n",
            "std                0.050014     0.176710  \n",
            "min                0.000000     0.000000  \n",
            "25%                0.024477     0.000000  \n",
            "50%                0.033798     0.000000  \n",
            "75%                0.052838     0.000000  \n",
            "max                1.000000     1.000000  \n",
            "\n",
            "[8 rows x 96 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename target column for clarity (first column is Bankrupt?)\n",
        "df.columns = df.columns.str.strip()  # Remove any whitespace\n",
        "target_col = \"Bankrupt?\""
      ],
      "metadata": {
        "id": "udnRidJNWXEk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target Distribution\n",
        "print(f\" Target Distribution:\\n{df[target_col].value_counts()}\")\n",
        "print(f\"\\n  Class Imbalance Ratio: {df[target_col].value_counts()[0] / df[target_col].value_counts()[1]:.1f}:1 (Non-Bankrupt:Bankrupt)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPENKdEZWPci",
        "outputId": "f822c427-a819-4d0e-c937-d1323b7c220a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Target Distribution:\n",
            "Bankrupt?\n",
            "0    6599\n",
            "1     220\n",
            "Name: count, dtype: int64\n",
            "\n",
            "  Class Imbalance Ratio: 30.0:1 (Non-Bankrupt:Bankrupt)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the there is an imbalance in target labels. Hence we will have to treat it."
      ],
      "metadata": {
        "id": "BI81TJUtAS6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "l376LJINPzdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]"
      ],
      "metadata": {
        "id": "nIbPbQv8PtxO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check and handle missing values\n",
        "missing = X.isnull().sum().sum()\n",
        "print(missing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq19W-6iP8mb",
        "outputId": "a656565e-06e6-459b-8d0b-c5d1fb43ee65"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No missing values found so did not perform any missing value imputation steps."
      ],
      "metadata": {
        "id": "pCHDgBtmAcKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ],
      "metadata": {
        "id": "mvJKkqH8RkU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Test Split (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "GulZRgvlRmIq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling"
      ],
      "metadata": {
        "id": "FvG1VV-XRsm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling (StandardScaler — zero mean, unit variance)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "64rTccnLRuAA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMOTE"
      ],
      "metadata": {
        "id": "z7VAXpAIRzVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using SMOTE to treat label imbalance"
      ],
      "metadata": {
        "id": "A0_nKokEAjw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "2jL4ICchRy1Y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.Series(y_train_res).value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjEbprErWmr9",
        "outputId": "7dd0a33e-3242-4ee5-a912-63faa67de75b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bankrupt?\n",
            "0    5279\n",
            "1    5279\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feedforward Neural Network (FNN / MLP) Model"
      ],
      "metadata": {
        "id": "I0e639cPR-I3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Taiwanese Bankruptcy dataset is structured tabular data with 95 numerical financial features, thus feedforward neural network is suitable for it."
      ],
      "metadata": {
        "id": "DnAr9HBJBDob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_dim):\n",
        "    model = Sequential([\n",
        "        # Input Layer\n",
        "        Dense(128, input_dim=input_dim, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # Hidden Layer 1\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # Hidden Layer 2\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        # Output Layer (Sigmoid for binary classification)\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_model(input_dim=X_train_res.shape[1])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "EmKViSqDR_rO",
        "outputId": "09db53f3-dc85-43a7-e9e8-a4a937bce4ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m12,288\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,425\u001b[0m (91.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,425</span> (91.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,041\u001b[0m (90.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,041</span> (90.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Neural Network"
      ],
      "metadata": {
        "id": "fRT9oD3NYCJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss', patience=15, restore_best_weights=True, verbose=1\n",
        ")\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.5, patience=7, verbose=1, min_lr=1e-6\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_res, y_train_res,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop, lr_scheduler],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMMiX61zSZ-O",
        "outputId": "8fd40e44-004f-465b-ce03-9e8bb5c7b798"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7903 - loss: 0.4352 - val_accuracy: 0.9697 - val_loss: 0.2409 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8866 - loss: 0.2730 - val_accuracy: 0.9607 - val_loss: 0.2371 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9069 - loss: 0.2242 - val_accuracy: 0.9920 - val_loss: 0.1347 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9202 - loss: 0.2003 - val_accuracy: 0.9891 - val_loss: 0.1280 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9281 - loss: 0.1778 - val_accuracy: 0.9986 - val_loss: 0.1008 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9350 - loss: 0.1652 - val_accuracy: 0.9991 - val_loss: 0.1141 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9472 - loss: 0.1446 - val_accuracy: 0.9995 - val_loss: 0.0790 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9527 - loss: 0.1290 - val_accuracy: 0.9976 - val_loss: 0.0663 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9575 - loss: 0.1211 - val_accuracy: 0.9943 - val_loss: 0.1004 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9614 - loss: 0.1085 - val_accuracy: 0.9995 - val_loss: 0.0712 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9675 - loss: 0.0967 - val_accuracy: 0.9967 - val_loss: 0.0624 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9621 - loss: 0.1052 - val_accuracy: 0.9995 - val_loss: 0.0787 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9682 - loss: 0.0959 - val_accuracy: 1.0000 - val_loss: 0.0447 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9696 - loss: 0.0911 - val_accuracy: 0.9991 - val_loss: 0.0448 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9716 - loss: 0.0824 - val_accuracy: 0.9995 - val_loss: 0.0651 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.0794 - val_accuracy: 0.9972 - val_loss: 0.0724 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0916 - val_accuracy: 0.9981 - val_loss: 0.0562 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9739 - loss: 0.0763 - val_accuracy: 1.0000 - val_loss: 0.0552 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.0676 - val_accuracy: 1.0000 - val_loss: 0.0531 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m111/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0703\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.0708 - val_accuracy: 0.9981 - val_loss: 0.0629 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.0627 - val_accuracy: 1.0000 - val_loss: 0.0458 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.0586 - val_accuracy: 0.9995 - val_loss: 0.0472 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.0537 - val_accuracy: 1.0000 - val_loss: 0.0347 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0524 - val_accuracy: 1.0000 - val_loss: 0.0379 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0500 - val_accuracy: 1.0000 - val_loss: 0.0409 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0484 - val_accuracy: 1.0000 - val_loss: 0.0234 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.0557 - val_accuracy: 1.0000 - val_loss: 0.0201 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0420 - val_accuracy: 1.0000 - val_loss: 0.0294 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9834 - loss: 0.0479 - val_accuracy: 1.0000 - val_loss: 0.0264 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0504 - val_accuracy: 1.0000 - val_loss: 0.0371 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0466 - val_accuracy: 1.0000 - val_loss: 0.0205 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.0402 - val_accuracy: 1.0000 - val_loss: 0.0209 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.0520 - val_accuracy: 1.0000 - val_loss: 0.0222 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m111/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0381\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9880 - loss: 0.0387 - val_accuracy: 1.0000 - val_loss: 0.0265 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0430 - val_accuracy: 1.0000 - val_loss: 0.0198 - learning_rate: 2.5000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9880 - loss: 0.0361 - val_accuracy: 1.0000 - val_loss: 0.0248 - learning_rate: 2.5000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0399 - val_accuracy: 1.0000 - val_loss: 0.0167 - learning_rate: 2.5000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.0389 - val_accuracy: 1.0000 - val_loss: 0.0160 - learning_rate: 2.5000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0292 - val_accuracy: 1.0000 - val_loss: 0.0202 - learning_rate: 2.5000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0346 - val_accuracy: 1.0000 - val_loss: 0.0199 - learning_rate: 2.5000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0378 - val_accuracy: 1.0000 - val_loss: 0.0150 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0315 - val_accuracy: 1.0000 - val_loss: 0.0176 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0307 - val_accuracy: 1.0000 - val_loss: 0.0161 - learning_rate: 2.5000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0297 - val_accuracy: 1.0000 - val_loss: 0.0187 - learning_rate: 2.5000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0274 - val_accuracy: 1.0000 - val_loss: 0.0171 - learning_rate: 2.5000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0343 - val_accuracy: 1.0000 - val_loss: 0.0114 - learning_rate: 2.5000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0308 - val_accuracy: 1.0000 - val_loss: 0.0177 - learning_rate: 2.5000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0355 - val_accuracy: 1.0000 - val_loss: 0.0132 - learning_rate: 2.5000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0335 - val_accuracy: 1.0000 - val_loss: 0.0183 - learning_rate: 2.5000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0306 - val_accuracy: 1.0000 - val_loss: 0.0130 - learning_rate: 2.5000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0292 - val_accuracy: 1.0000 - val_loss: 0.0190 - learning_rate: 2.5000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0193 - learning_rate: 2.5000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m127/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0267\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0267 - val_accuracy: 1.0000 - val_loss: 0.0127 - learning_rate: 2.5000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0258 - val_accuracy: 1.0000 - val_loss: 0.0107 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0206 - val_accuracy: 1.0000 - val_loss: 0.0154 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0239 - val_accuracy: 1.0000 - val_loss: 0.0149 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0172 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 0.0122 - learning_rate: 1.2500e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0219 - val_accuracy: 1.0000 - val_loss: 0.0110 - learning_rate: 1.2500e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0210 - val_accuracy: 1.0000 - val_loss: 0.0119 - learning_rate: 1.2500e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 0.0093 - learning_rate: 1.2500e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0173 - val_accuracy: 1.0000 - val_loss: 0.0114 - learning_rate: 1.2500e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0219 - val_accuracy: 1.0000 - val_loss: 0.0105 - learning_rate: 1.2500e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0265 - val_accuracy: 1.0000 - val_loss: 0.0105 - learning_rate: 1.2500e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0225 - val_accuracy: 1.0000 - val_loss: 0.0107 - learning_rate: 1.2500e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0241 - val_accuracy: 1.0000 - val_loss: 0.0117 - learning_rate: 1.2500e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0107 - learning_rate: 1.2500e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m124/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9937 - loss: 0.0218\n",
            "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0220 - val_accuracy: 1.0000 - val_loss: 0.0109 - learning_rate: 1.2500e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0260 - val_accuracy: 1.0000 - val_loss: 0.0100 - learning_rate: 6.2500e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0175 - val_accuracy: 1.0000 - val_loss: 0.0078 - learning_rate: 6.2500e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0083 - learning_rate: 6.2500e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0164 - val_accuracy: 1.0000 - val_loss: 0.0104 - learning_rate: 6.2500e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0194 - val_accuracy: 1.0000 - val_loss: 0.0100 - learning_rate: 6.2500e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0223 - val_accuracy: 1.0000 - val_loss: 0.0104 - learning_rate: 6.2500e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0199 - val_accuracy: 1.0000 - val_loss: 0.0101 - learning_rate: 6.2500e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0187 - val_accuracy: 1.0000 - val_loss: 0.0105 - learning_rate: 6.2500e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0260\n",
            "Epoch 77: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9893 - loss: 0.0260 - val_accuracy: 1.0000 - val_loss: 0.0119 - learning_rate: 6.2500e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0116 - learning_rate: 3.1250e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0180 - val_accuracy: 1.0000 - val_loss: 0.0102 - learning_rate: 3.1250e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0219 - val_accuracy: 1.0000 - val_loss: 0.0099 - learning_rate: 3.1250e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0101 - learning_rate: 3.1250e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0173 - val_accuracy: 1.0000 - val_loss: 0.0100 - learning_rate: 3.1250e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0260 - val_accuracy: 1.0000 - val_loss: 0.0101 - learning_rate: 3.1250e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m114/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0234\n",
            "Epoch 84: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0235 - val_accuracy: 1.0000 - val_loss: 0.0121 - learning_rate: 3.1250e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0170 - val_accuracy: 1.0000 - val_loss: 0.0099 - learning_rate: 1.5625e-05\n",
            "Epoch 85: early stopping\n",
            "Restoring model weights from the end of the best epoch: 70.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Predictions"
      ],
      "metadata": {
        "id": "GKbD14f7YeKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(X_test_scaled).flatten()\n",
        "y_pred      = (y_pred_prob >= 0.5).astype(int)"
      ],
      "metadata": {
        "id": "5XQLwjhDYh18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21523d62-f321-4cc0-c979-9191ba1a75ae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Evaluation Metrics (Classification)"
      ],
      "metadata": {
        "id": "arEN6HPkYkGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy :', accuracy_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('Recall   :', recall_score(y_test, y_pred))\n",
        "print('F1-score :', f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgRJwEW0S19U",
        "outputId": "edddc9be-6220-4ac9-ef8c-5ba1761a7cc7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.9655425219941349\n",
            "Precision: 0.4482758620689655\n",
            "Recall   : 0.29545454545454547\n",
            "F1-score : 0.3561643835616438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "- Feedforward Neural Network works for Taiwanese Bankruptcy Prediction dataset to classify companies as bankrupt or non-bankrupt using 95 financial ratios, with SMOTE handling the severe class imbalance.\n",
        "- The model was evaluated using Accuracy, Precision, Recall, and F1-Score, demonstrating that FNN is an effective and reliable approach for financial risk prediction, where Recall holds the highest importance to minimize the cost of missing true bankruptcy cases."
      ],
      "metadata": {
        "id": "fdY6DMHLBco4"
      }
    }
  ]
}